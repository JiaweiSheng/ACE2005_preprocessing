{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tag =0\n",
    "id_dep = 0\n",
    "position = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"Let me tell you, what trips to Walter Reed taught me was, that whoever thought up the term, the law of unintended consequences it pertains to war.\",\n",
    "        \"Our president has repeatedly, for example, relied on a man whom you're aware, Hussein Kamel, Saddam Hussein's son in law, leader of the Iraq arms program who defected for a time.\",\n",
    "        \"And gave us a whole lot of information and then went home and his father in law killed him.\",\n",
    "        \"Clinton suffered greatly over the 19 Rangers that died, 18 on the 3rd of October and Matt Reersen (ph) three days later.\",\n",
    "        \"He was probably running around being shot at for days on end in Falluja.\",\n",
    "        \"I would have shot the insurgent too.\",\n",
    "        \"For that I believe the Marines should handle dead and wounded insurgents by any means necessary to ensure their own safety and prevent a possible ambush.\",\n",
    "         \"Tell that to the family of Margaret Hassan, the school teacher who was brutally tortured and then slaughtered by these same guys, they ain't so bad are they Chris Matthews?\",\n",
    "        \"He lost an election to a dead man.\",\n",
    "        \"Paul, as I understand your definition of a political    of a professional politician based on that is somebody who is elected to public office.\",\n",
    "        \"well, security is tight as exxon mobil shareholders meet today in dallas.\",\n",
    "        \"yesterday, protesters blocked the entrance to protest what they claim is the company's inaction against global warming.\",]\n",
    "\n",
    "with StanfordCoreNLP('E:/LAP_TRINH/stanford-corenlp-full-2018-10-05', memory='8g', timeout=30000) as nlp:\n",
    "    for sent in sents[:1]:\n",
    "        nlp_text = nlp.annotate(sent, properties={'annotators': 'tokenize,ssplit,pos, parse'})\n",
    "        nlp_res = json.loads(nlp_text)\n",
    "\n",
    "\n",
    "        tags = dict()\n",
    "        deps = []\n",
    "        for word in nlp_res['sentences'][0]['tokens']:\n",
    "            if word['pos'] in [',','.']:\n",
    "                continue\n",
    "            if word['pos'] in ['PRP$','WP$']:\n",
    "                word['pos'] =word['pos'][:-1]+'_'\n",
    "            tags.update({(word['index'],word['originalText']):['T'+str(id_tag), word['pos'], word['characterOffsetBegin']+position, word['characterOffsetEnd']+position]})\n",
    "            id_tag +=1\n",
    "\n",
    "        for dep in nlp_res['sentences'][0]['basicDependencies']:\n",
    "            governor = 'R'+str(id_dep)\n",
    "            if dep['dep'] in ['ROOT', 'punct']:\n",
    "                continue\n",
    "            if len(dep['dep'].split(':')) >1:\n",
    "                split_dep = dep['dep'].split(':')\n",
    "                dep['dep'] = '-'.join(d for d in split_dep) \n",
    "            deps.append([governor,dep['dep'], 'Arg1:'+tags[(dep['governor'],dep['governorGloss'])][0], 'Arg2:'+tags[(dep['dependent'],dep['dependentGloss'])][0] ])\n",
    "            id_dep +=1\n",
    "        position +=nlp_res['sentences'][0]['tokens'][-1]['characterOffsetEnd'] +2\n",
    "\n",
    "\n",
    "        with open('D:/Machine_learning/brat-v1.3_Crunchy_Frog/data/dependency_check/dep.ann', 'a') as f:\n",
    "            for word in tags:\n",
    "                tag = tags[word]\n",
    "                f.write(str(tag[0])+'\\t'+tag[1]+' '+str(tag[2])+' '+str(tag[3])+'\\t'+word[1]+'\\n')\n",
    "            for dep in deps:\n",
    "                f.write(dep[0]+'\\t'+dep[1]+' '+dep[2]+' '+dep[3]+'\\n')\n",
    "        with open('D:/Machine_learning/brat-v1.3_Crunchy_Frog/data/dependency_check/dep.txt', 'a') as f:\n",
    "            f.write(sent+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['index', 'parse', 'basicDependencies', 'enhancedDependencies', 'enhancedPlusPlusDependencies', 'tokens'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_res['sentences'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 1, 'dependentGloss': 'Let'}\n",
      "{'dep': 'nsubj', 'governor': 3, 'governorGloss': 'tell', 'dependent': 2, 'dependentGloss': 'me'}\n",
      "{'dep': 'ccomp', 'governor': 1, 'governorGloss': 'Let', 'dependent': 3, 'dependentGloss': 'tell'}\n",
      "{'dep': 'dobj', 'governor': 3, 'governorGloss': 'tell', 'dependent': 4, 'dependentGloss': 'you'}\n",
      "{'dep': 'punct', 'governor': 3, 'governorGloss': 'tell', 'dependent': 5, 'dependentGloss': ','}\n",
      "{'dep': 'dobj', 'governor': 11, 'governorGloss': 'taught', 'dependent': 6, 'dependentGloss': 'what'}\n",
      "{'dep': 'nsubj', 'governor': 11, 'governorGloss': 'taught', 'dependent': 7, 'dependentGloss': 'trips'}\n",
      "{'dep': 'case', 'governor': 10, 'governorGloss': 'Reed', 'dependent': 8, 'dependentGloss': 'to'}\n",
      "{'dep': 'compound', 'governor': 10, 'governorGloss': 'Reed', 'dependent': 9, 'dependentGloss': 'Walter'}\n",
      "{'dep': 'nmod', 'governor': 7, 'governorGloss': 'trips', 'dependent': 10, 'dependentGloss': 'Reed'}\n",
      "{'dep': 'ccomp', 'governor': 3, 'governorGloss': 'tell', 'dependent': 11, 'dependentGloss': 'taught'}\n",
      "{'dep': 'nsubj', 'governor': 13, 'governorGloss': 'was', 'dependent': 12, 'dependentGloss': 'me'}\n",
      "{'dep': 'ccomp', 'governor': 11, 'governorGloss': 'taught', 'dependent': 13, 'dependentGloss': 'was'}\n",
      "{'dep': 'punct', 'governor': 13, 'governorGloss': 'was', 'dependent': 14, 'dependentGloss': ','}\n",
      "{'dep': 'mark', 'governor': 28, 'governorGloss': 'pertains', 'dependent': 15, 'dependentGloss': 'that'}\n",
      "{'dep': 'nsubj', 'governor': 17, 'governorGloss': 'thought', 'dependent': 16, 'dependentGloss': 'whoever'}\n",
      "{'dep': 'advcl', 'governor': 28, 'governorGloss': 'pertains', 'dependent': 17, 'dependentGloss': 'thought'}\n",
      "{'dep': 'compound-prt', 'governor': 17, 'governorGloss': 'thought', 'dependent': 18, 'dependentGloss': 'up'}\n",
      "{'dep': 'det', 'governor': 20, 'governorGloss': 'term', 'dependent': 19, 'dependentGloss': 'the'}\n",
      "{'dep': 'dobj', 'governor': 17, 'governorGloss': 'thought', 'dependent': 20, 'dependentGloss': 'term'}\n",
      "{'dep': 'punct', 'governor': 20, 'governorGloss': 'term', 'dependent': 21, 'dependentGloss': ','}\n",
      "{'dep': 'det', 'governor': 23, 'governorGloss': 'law', 'dependent': 22, 'dependentGloss': 'the'}\n",
      "{'dep': 'appos', 'governor': 20, 'governorGloss': 'term', 'dependent': 23, 'dependentGloss': 'law'}\n",
      "{'dep': 'case', 'governor': 26, 'governorGloss': 'consequences', 'dependent': 24, 'dependentGloss': 'of'}\n",
      "{'dep': 'amod', 'governor': 26, 'governorGloss': 'consequences', 'dependent': 25, 'dependentGloss': 'unintended'}\n",
      "{'dep': 'nmod', 'governor': 23, 'governorGloss': 'law', 'dependent': 26, 'dependentGloss': 'consequences'}\n",
      "{'dep': 'nsubj', 'governor': 28, 'governorGloss': 'pertains', 'dependent': 27, 'dependentGloss': 'it'}\n",
      "{'dep': 'ccomp', 'governor': 13, 'governorGloss': 'was', 'dependent': 28, 'dependentGloss': 'pertains'}\n",
      "{'dep': 'case', 'governor': 30, 'governorGloss': 'war', 'dependent': 29, 'dependentGloss': 'to'}\n",
      "{'dep': 'nmod', 'governor': 28, 'governorGloss': 'pertains', 'dependent': 30, 'dependentGloss': 'war'}\n",
      "{'dep': 'punct', 'governor': 1, 'governorGloss': 'Let', 'dependent': 31, 'dependentGloss': '.'}\n"
     ]
    }
   ],
   "source": [
    "set_tag = set()\n",
    "for t in nlp_res['sentences'][0]['basicDependencies']:\n",
    "    set_tag.update([t['dep']])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROOT',\n",
       " 'advcl',\n",
       " 'amod',\n",
       " 'appos',\n",
       " 'case',\n",
       " 'ccomp',\n",
       " 'compound',\n",
       " 'compound-prt',\n",
       " 'det',\n",
       " 'dobj',\n",
       " 'mark',\n",
       " 'nmod',\n",
       " 'nsubj',\n",
       " 'punct'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Tom Andrews, I think we all realize that a government does n't go to war a nation goes to war.\"\n",
    "with StanfordCoreNLP('E:/LAP_TRINH/stanford-corenlp-full-2018-10-05', memory='8g', timeout=30000) as nlp:\n",
    "        nlp_text = nlp.annotate(a, properties={'annotators': 'tokenize,ssplit,pos, parse'})\n",
    "        nlp_res = json.loads(nlp_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dep': 'ROOT', 'governor': 0, 'governorGloss': 'ROOT', 'dependent': 19, 'dependentGloss': 'goes'}\n",
      "{'dep': 'compound', 'governor': 2, 'governorGloss': 'Andrews', 'dependent': 1, 'dependentGloss': 'Tom'}\n",
      "{'dep': 'nsubj', 'governor': 19, 'governorGloss': 'goes', 'dependent': 2, 'dependentGloss': 'Andrews'}\n",
      "{'dep': 'punct', 'governor': 19, 'governorGloss': 'goes', 'dependent': 3, 'dependentGloss': ','}\n",
      "{'dep': 'nsubj', 'governor': 5, 'governorGloss': 'think', 'dependent': 4, 'dependentGloss': 'I'}\n",
      "{'dep': 'parataxis', 'governor': 19, 'governorGloss': 'goes', 'dependent': 5, 'dependentGloss': 'think'}\n",
      "{'dep': 'nsubj', 'governor': 8, 'governorGloss': 'realize', 'dependent': 6, 'dependentGloss': 'we'}\n",
      "{'dep': 'advmod', 'governor': 8, 'governorGloss': 'realize', 'dependent': 7, 'dependentGloss': 'all'}\n",
      "{'dep': 'ccomp', 'governor': 5, 'governorGloss': 'think', 'dependent': 8, 'dependentGloss': 'realize'}\n",
      "{'dep': 'mark', 'governor': 14, 'governorGloss': 'go', 'dependent': 9, 'dependentGloss': 'that'}\n",
      "{'dep': 'det', 'governor': 11, 'governorGloss': 'government', 'dependent': 10, 'dependentGloss': 'a'}\n",
      "{'dep': 'nsubj', 'governor': 14, 'governorGloss': 'go', 'dependent': 11, 'dependentGloss': 'government'}\n",
      "{'dep': 'aux', 'governor': 14, 'governorGloss': 'go', 'dependent': 12, 'dependentGloss': 'does'}\n",
      "{'dep': 'neg', 'governor': 14, 'governorGloss': 'go', 'dependent': 13, 'dependentGloss': \"n't\"}\n",
      "{'dep': 'ccomp', 'governor': 8, 'governorGloss': 'realize', 'dependent': 14, 'dependentGloss': 'go'}\n",
      "{'dep': 'case', 'governor': 16, 'governorGloss': 'war', 'dependent': 15, 'dependentGloss': 'to'}\n",
      "{'dep': 'nmod', 'governor': 14, 'governorGloss': 'go', 'dependent': 16, 'dependentGloss': 'war'}\n",
      "{'dep': 'det', 'governor': 18, 'governorGloss': 'nation', 'dependent': 17, 'dependentGloss': 'a'}\n",
      "{'dep': 'nsubj', 'governor': 19, 'governorGloss': 'goes', 'dependent': 18, 'dependentGloss': 'nation'}\n",
      "{'dep': 'case', 'governor': 21, 'governorGloss': 'war', 'dependent': 20, 'dependentGloss': 'to'}\n",
      "{'dep': 'nmod', 'governor': 19, 'governorGloss': 'goes', 'dependent': 21, 'dependentGloss': 'war'}\n",
      "{'dep': 'punct', 'governor': 19, 'governorGloss': 'goes', 'dependent': 22, 'dependentGloss': '.'}\n"
     ]
    }
   ],
   "source": [
    "set_tag = set()\n",
    "for t in nlp_res['sentences'][0]['basicDependencies']:\n",
    "    set_tag.update([t['dep']])\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n",
      "Y\n",
      "\n",
      "Default download directory: C:\\Users\\dell\\stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: C:\\Users\\dell\\stanfordnlp_resources\\en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235M/235M [01:56<00:00, 1.92MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: C:\\Users\\dell\\stanfordnlp_resources\\en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "source": [
    "stanfordnlp.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\dell\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\dell\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\dell\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\dell\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\dell\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt_parser.pt', 'pretrain_path': 'C:\\\\Users\\\\dell\\\\stanfordnlp_resources\\\\en_ewt_models\\\\en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\cuda\\LegacyDefinitions.cpp:19: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Barack', '4', 'nsubj:pass')\n",
      "('Obama', '1', 'flat')\n",
      "('was', '4', 'aux:pass')\n",
      "('born', '0', 'root')\n",
      "('in', '6', 'case')\n",
      "('Hawaii', '4', 'obl')\n",
      "('.', '4', 'punct')\n"
     ]
    }
   ],
   "source": [
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'basicDependencies'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-169db50e7afe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicDependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'basicDependencies'"
     ]
    }
   ],
   "source": [
    "doc.sentences.basicDependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# with open(test_files+'.sgm', 'r') as f:\n",
    "#     soup = BeautifulSoup(f.read())\n",
    "#     text = soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = soup.findAll('speaker')\n",
    "# for tag in tags:\n",
    "#     tag.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = soup.text\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = {'Numeric:Percent', 'Job-Title', 'Crime', 'Sentence', 'Numeric:Money', 'Contact-Info:E-Mail', 'Contact-Info:Phone-Number'}\n",
    "# a.update({'Contact-Info:URL', 'Numeric:Percent', 'Job-Title', 'Crime', 'Sentence', 'Numeric:Money'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Contact-Info:E-Mail',\n",
       " 'Contact-Info:Phone-Number',\n",
       " 'Contact-Info:URL',\n",
       " 'Crime',\n",
       " 'Job-Title',\n",
       " 'Numeric:Money',\n",
       " 'Numeric:Percent',\n",
       " 'Sentence'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
